{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exoplanet TSO Pipeline\n",
    "\n",
    "**NEW METHOD**\n",
    "\n",
    "1. Develop a single routine that inputs \n",
    "    1. String (fits file name) or array (loaded fits file)\n",
    "    2. The expected location of the star (center of frame is default)\n",
    "    3. Subframe size (for better center fitting)\n",
    "    4. List of aperture radii (or a float for a single aperture radii)\n",
    "2. This routine will load a single fits file or list of fits files (one at a time; recursive?)\n",
    "3. For each single, or recursively for a list of fits files, \n",
    "    1. load the data.\n",
    "    2. Computer the time element\n",
    "    3. subtract the background (store background level)\n",
    "    4. isolate the star into a subframe\n",
    "    5. Cross-correlate a Gaussian (or synthetic psf) with the image to find predicted center (store CC center)\n",
    "    6. Gaussian fit to subframe, starting at CC center (store GS center, width, amplitude)\n",
    "    7. Perform apeture photometry with each radius given at the beginning (store aperture radii as a function of radius)\n",
    "\n",
    "This routine ensures that the user can manipulate the inputs as needed. Users can either send a single fits array, a set of fits array, a single string with the location of a fits file, or a list of strings with the location of several fits files.\n",
    "\n",
    "The result will be a 'DataFrame' of the same depth as the input structure, containing (labeled as keys) the \n",
    "- 'sky background'\n",
    "- 'cross correlation center'\n",
    "- 'gaussian center'\n",
    "- 'gaussian width'\n",
    "- 'gaussian ampitude'\n",
    "- 'aperture photometry dictionary' or 'aperture photometry dataframe'\n",
    "    - the keys to the aperture photometry dictionary or data frame will be the float values of the aperture radii\n",
    "- 'time' (in days?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OLD METHOD - for Posterity and External Comparison**\n",
    "1.  Input data from file directory from user\n",
    "2.  Access that file directory and grab all file names\n",
    "     -- possible include a data file \n",
    "3.  Sequentially open all fits file in that directory (or from the data file)\n",
    "4.  During the opening process, store the data frame(s) necessary for production of time series\n",
    "5.  Remove the original data from RAM (too much space)\n",
    "6.  Subtract median background\n",
    "7.  Cross-Correlated Gaussian with center of image\n",
    "8.  Fit a Gaussian to center of image, starting from Cross-Correlation solution\n",
    "9.  Integrate (using 'exact') the aperture photometry\n",
    "10. Store aperture photometry, gaussian centers, cross-correlation centers, gaussian widths, gaussian heights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load All Necessary Libraries and Functions\n",
    "---\n",
    "\n",
    "    `pylab`      : combination of array manipulation and plotting functions\n",
    "    `matplotlib` : specialized plotting functions\n",
    "    `numpy`      : array more manipulation functions\n",
    "    `pandas`     : dataframe -- more advanced array / table -- functions\n",
    "    `photutils`  : astropy associated package for aperture photometry\n",
    "    `astropy`    : `modeling` : access linear and gaussian functions with astropy formatting\n",
    "                   `fitting`  : access to astropy fitting routines\n",
    "    `glob`       : grab list of files in directory\n",
    "\n",
    "    -- Not Used Yet --\n",
    "    `astroML`    : better histogram function for plotting\n",
    "    `sklearn`    : `externals`: imports operating system (storage) level function (i.e. joblib)\n",
    "    `statsmodels`: `robust`   : robust statistical modeling packages; `scale.mad` == median average distance\n",
    "    `sys`        : python-os level functions (i.e. path)\n",
    "    `time`       : compute and convert current timestamps from python / os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matplotlib for Plotting\n",
    "%matplotlib inline\n",
    "from pylab              import gcf, sort, linspace, indices, std, empty, concatenate, pi, sqrt, ones, diag, inf\n",
    "from pylab              import rcParams, array, get_current_fig_manager, twinx, figure, subplots_adjust\n",
    "\n",
    "from matplotlib.ticker  import MaxNLocator\n",
    "from matplotlib         import style\n",
    "from matplotlib         import pyplot as plt\n",
    "\n",
    "# Numpy & Pandas for Array and DataFrame Manipulation\n",
    "from numpy              import min, max, median, mean, zeros, empty\n",
    "from numpy              import ones, where, arange, indices\n",
    "from pandas             import DataFrame, read_csv, scatter_matrix\n",
    "\n",
    "# Astropy for Aperture Photometry and Fits read/write\n",
    "from photutils          import CircularAperture, aperture_photometry\n",
    "# from astroML.plotting   import hist\n",
    "from astropy.modeling   import models, fitting\n",
    "from astropy.io         import fits\n",
    "\n",
    "# Built in Libraries for directory\n",
    "from glob               import glob\n",
    "\n",
    "# Adam Ginsburg\n",
    "from image_registration import cross_correlation_shifts\n",
    "\n",
    "# Data Storage from Sci-kits\n",
    "# from sklearn.externals import joblib\n",
    "\n",
    "# Style Components\n",
    "# from seaborn            import *\n",
    "\n",
    "# from socket             import gethostname\n",
    "# from statsmodels.robust import scale\n",
    "# from sys                import exit, stdout\n",
    "# from time               import time\n",
    "\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example input for the requests below. The directory contains a collection of fits files within it\n",
    "    - only works on my laptop\n",
    "    - soon to 'upgraded' to working on the server\n",
    "\n",
    "'/path/to/fits/files/'\n",
    "\n",
    "There is also a test file in the current working directory named `'fits_input_file.txt'`. It was creating using the bash 'script'\n",
    "\n",
    "```bash\n",
    "cd /path/to/fits/files/\n",
    "ls > fits_input_file.txt\n",
    "```\n",
    "\n",
    "---\n",
    "Responding to the inquiry with (including appostraphes) either \n",
    "\n",
    "`'fits_input_file.txt'` \n",
    "\n",
    "or \n",
    "\n",
    "`'/path/to/fits/files/'` \n",
    "\n",
    "is successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request Directory with a Set of Fits Files OR a Text File with the Same List\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_data_file_types = ['.txt', '.dat', '.csv']\n",
    "found       = False\n",
    "DataDir     = input()\n",
    "\n",
    "for filetype in list_of_data_file_types:\n",
    "    if filetype in DataDir:\n",
    "        fitsfilenames = list(read_csv(DataDir))\n",
    "        found = True\n",
    "\n",
    "if not found:\n",
    "    fitsfilenames = glob(DataDir+'/*')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Julian Data from Header\n",
    "---\n",
    "\n",
    "This function is a wrapper for `julian_date` in the `jd.py` package (soon to be converted to `julian_date.py` package.\n",
    "It's utility is in taking in the time stamps from the headers and converting them to the julian date; to be saved in the 'master' data frame below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Previous version of julian date calculation. Required extra libraries.\n",
    "```python\n",
    "def get_julian_date_from_header(header):\n",
    "    from jd import julian_date\n",
    "    fitsDate    = header['DATE-OBS']\n",
    "    startTimeStr= header['TIME-OBS']\n",
    "    endTimeStr  = header['TIME-END']\n",
    "    \n",
    "    yy,mm,dd    = fitsDate.split('-')\n",
    "    \n",
    "    hh1,mn1,ss1 = array(startTimeStr.split(':')).astype(float)\n",
    "    hh2,mn2,ss2 = array(endTimeStr.split(':')).astype(float)\n",
    "    \n",
    "    startDate   = julian_date(yy,mm,dd,hh1,mn1,ss1)\n",
    "    endDate     = julian_date(yy,mm,dd,hh2,mn2,ss2)\n",
    "\n",
    "    return startDate, endDate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_julian_date_from_gregorian_date(*date):\n",
    "    \"\"\"gd2jd.py converts a UT Gregorian date to Julian date.\n",
    "    \n",
    "    Functions for JD <-> GD conversion, \n",
    "      courtesy of Ian Crossfield at \n",
    "      http://www.astro.ucla.edu/~ianc/python/_modules/date.html\n",
    "    \n",
    "    Downloaded from Marshall Perrin Github at\n",
    "        https://github.com/mperrin/misc_astro/blob/master/idlastro_ports/gd2jd.py\n",
    "    \n",
    "    Usage: gd2jd.py (2009, 02, 25, 01, 59, 59)\n",
    "\n",
    "    To get the current Julian date:\n",
    "        import time\n",
    "        gd2jd(time.gmtime())\n",
    "\n",
    "    Hours, minutes and/or seconds can be omitted -- if so, they are\n",
    "    assumed to be zero.\n",
    "\n",
    "    Year and month are converted to type INT, but all others can be\n",
    "    type FLOAT (standard practice would suggest only the final element\n",
    "    of the date should be float)\n",
    "    \"\"\"\n",
    "    verbose=False\n",
    "    if verbose: print date\n",
    "    #print date[0]\n",
    "    #date = date[0]\n",
    "\n",
    "    date = list(date)\n",
    "    \n",
    "    if len(date)<3:\n",
    "        print \"You must enter a date of the form (2009, 02, 25)!\"\n",
    "        return -1\n",
    "    elif len(date)==3:\n",
    "        for ii in range(3): date.append(0)\n",
    "    elif len(date)==4:\n",
    "        for ii in range(2): date.append(0)\n",
    "    elif len(date)==5:\n",
    "        date.append(0)\n",
    "\n",
    "    yyyy = int(date[0])\n",
    "    mm = int(date[1])\n",
    "    dd = float(date[2])\n",
    "    hh = float(date[3])\n",
    "    min = float(date[4])\n",
    "    sec = float(date[5])\n",
    "\n",
    "    UT=hh+min/60+sec/3600\n",
    "\n",
    "\n",
    "    total_seconds=hh*3600+min*60+sec\n",
    "    fracday=total_seconds/86400\n",
    "\n",
    "    if (100*yyyy+mm-190002.5)>0:\n",
    "        sig=1\n",
    "    else:\n",
    "        sig=-1\n",
    "\n",
    "    JD = 367*yyyy - int(7*(yyyy+int((mm+9)/12))/4) + int(275*mm/9) + dd + 1721013.5 + UT/24 - 0.5*sig +0.5\n",
    "\n",
    "    months=[\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \n",
    "                \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "    # Now calculate the fractional year. Do we have a leap year?\n",
    "    daylist=[31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "    daylist2=[31,29,31,30,31,30,31,31,30,31,30,31]\n",
    "    if (yyyy%4 != 0):\n",
    "        days=daylist2\n",
    "    elif (yyyy%400 == 0):\n",
    "        days=daylist2\n",
    "    elif (yyyy%100 == 0):\n",
    "        days=daylist\n",
    "    else:\n",
    "        days=daylist2\n",
    "\n",
    "    daysum=0\n",
    "    for y in range(mm-1):\n",
    "        daysum=daysum+days[y]\n",
    "    daysum=daysum+dd-1+UT/24\n",
    "\n",
    "    if days[1]==29:\n",
    "        fracyear=yyyy+daysum/366\n",
    "    else:\n",
    "        fracyear=yyyy+daysum/365\n",
    "    if verbose: \n",
    "        print yyyy,mm,dd,hh,min,sec\n",
    "        print \"UT=\"+`UT`\n",
    "        print \"Fractional day: %f\" % fracday\n",
    "        print \"\\n\"+months[mm-1]+\" %i, %i, %i:%i:%i UT = JD %f\" % (dd, yyyy, hh, min, sec, JD),\n",
    "        print \" = \" + `fracyear`+\"\\n\"\n",
    "    # print dd,mm,yyyy, hh,min,sec, UT\n",
    "\n",
    "\n",
    "\n",
    "    return JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_julian_date_from_header(header):\n",
    "    from jd import julian_date\n",
    "    fitsDate    = header['DATE-OBS']\n",
    "    startTimeStr= header['TIME-OBS']\n",
    "    endTimeStr  = header['TIME-END']\n",
    "    \n",
    "    yyyy, mm , dd   = fitsDate.split('-')\n",
    "    \n",
    "    hh1 , mn1, ss1  = array(startTimeStr.split(':')).astype(float)\n",
    "    hh2 , mn2, ss2  = array(endTimeStr.split(':')).astype(float)\n",
    "    \n",
    "    yyyy  = float(yyyy)\n",
    "    mm    = float(mm)\n",
    "    dd    = float(dd)\n",
    "    \n",
    "    hh1   = float(hh1)\n",
    "    mn1   = float(mn1)\n",
    "    ss1   = float(ss1)\n",
    "    \n",
    "    hh2   = float(hh2)\n",
    "    mn2   = float(mn2)\n",
    "    ss2   = float(ss2)\n",
    "    \n",
    "    startDate   = get_julian_date_from_gregorian_date(yyyy,mm,dd,hh1,mn1,ss1)\n",
    "    endDate     = get_julian_date_from_gregorian_date(yyyy,mm,dd,hh2,mn2,ss2)\n",
    "\n",
    "    return startDate, endDate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data / Gaussian Fit / AperturePhot Image\n",
    "---\n",
    "\n",
    "This function is the **crux** of the entire algorithm. The operation takes in one fits file name and outputs its time stamp, aperture photometry, gaussian centering / widths / amplitude, cross-correlation centering, and background subtracted values.  The routine does the following:\n",
    "\n",
    "1. Input:\n",
    "    1. String (fits file name) or array (loaded fits file)\n",
    "    2. The expected location of the star (center of frame is default)\n",
    "    3. Subframe size (for better center fitting)\n",
    "    4. List of aperture radii (or a float for a single aperture radii)\n",
    "2. Operation:\n",
    "    1. load the data.\n",
    "    2. Computer the time element\n",
    "    3. subtract the background (store background level)\n",
    "    4. isolate the star into a subframe\n",
    "    5. Cross-correlate a Gaussian (or synthetic psf) with the image to find predicted center (store CC center)\n",
    "    6. Gaussian fit to subframe, starting at CC center (store GS center, width, amplitude)\n",
    "    7. Perform apeture photometry with each radius given at the beginning (store aperture radii as a function of radius)\n",
    "3. Output\n",
    "    1. time stamp\n",
    "    2. aperture photometry\n",
    "    3. gaussian amplitude\n",
    "    4. gaussian centering\n",
    "    5. gaussian widths\n",
    "    6. cross-correlation centering\n",
    "    7. background subtracted values.\n",
    "\n",
    "This routine ensures that the user can manipulate the inputs as needed. Users can either send a single fits array, a set of fits array, a single string with the location of a fits file, or a list of strings with the location of several fits files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_fit_phot_time(fitsfile, guesscenter = None, subframesize = [10,10], aperrad = [5], \n",
    "                           nGroupsBig = 100, stddev0 = 2.0):\n",
    "    y,x     = 0,1\n",
    "    zero    = 0\n",
    "    day2sec = 86400.\n",
    "    k       = int(fitsfile.split('_I')[-1][:3])\n",
    "    \n",
    "    fitsname      = fitsfile.split('/')[-1]\n",
    "    fitsfile      = fits.open(fitsfile)\n",
    "    startJD,endJD = get_julian_date_from_header(fitsfile[0].header)\n",
    "    timeSpan      = (endJD - startJD)*day2sec/nGroupsBig\n",
    "    time          = startJD  + timeSpan*(k+0.5) / day2sec - 2450000.\n",
    "\n",
    "#     print '\\nNEED to control for multiframe arrays; maybe request only SLP\\n'\n",
    "    dataframe     = fitsfile[0].data[2] - fitsfile[0].data[0]\n",
    "    skybg         = np.median(dataframe)\n",
    "    \n",
    "    imagecenter   = 0.5*array(dataframe.shape)\n",
    "    if guesscenter == None:\n",
    "        guesscenter = imagecenter\n",
    "    \n",
    "    subframe      = dataframe[guesscenter[y]-subframesize[y]:guesscenter[y]+subframesize[y],\n",
    "                              guesscenter[y]-subframesize[x]:guesscenter[y]+subframesize[x]].copy()\n",
    "    \n",
    "    # ysize, xsize  = fitsfile[0].data.shape\n",
    "    yinds0, xinds0= indices(dataframe.shape)\n",
    "    yinds         = yinds0[guesscenter[y]-subframesize[y]:guesscenter[y]+subframesize[y],\n",
    "                           guesscenter[y]-subframesize[x]:guesscenter[y]+subframesize[x]]\n",
    "    xinds         = xinds0[guesscenter[y]-subframesize[y]:guesscenter[y]+subframesize[y],\n",
    "                           guesscenter[y]-subframesize[x]:guesscenter[y]+subframesize[x]]\n",
    "    \n",
    "    fitter        = fitting.LevMarLSQFitter()\n",
    "    plane         = models.Linear1D\n",
    "    gauss0        = models.Gaussian2D(amplitude = fitsfile[0].data.max(), \n",
    "                                      x_mean    = guesscenter[x], \n",
    "                                      y_mean    = guesscenter[y],\n",
    "                                      x_stddev  = stddev0       ,\n",
    "                                      y_stddev  = stddev0       ,\n",
    "                                      theta     = zero)\n",
    "    \n",
    "    CCCenter      = cross_correlation_shifts(gauss0(xinds, yinds), subframe) + imagecenter\n",
    "    CCCenter      = CCCenter[::-1] # need in order to associate y = 1, x = 0\n",
    "    \n",
    "    gauss1        = fitter(gauss0, xinds, yinds, subframe - skybg)\n",
    "    \n",
    "    circCenter     = gauss1.parameters[1:3][::-1] - imagecenter + subframesize\n",
    "    \n",
    "    circaper       = CircularAperture(circCenter, aperrad[0])\n",
    "    aperphot       = aperture_photometry(data=subframe - skybg, apertures=circaper)\n",
    "    del fitsfile[0].data\n",
    "    fitsfile.close()\n",
    "    del fitsfile\n",
    "    \n",
    "    return fitsname, float(aperphot['aperture_sum']), time, gauss1.amplitude.value, gauss1.y_mean.value, \\\n",
    "            gauss1.x_mean.value, abs(gauss1.y_stddev.value), abs(gauss1.x_stddev.value), \\\n",
    "            CCCenter[1], CCCenter[0], skybg\n",
    "\n",
    "#     return time, aperphot['aperture_sum'], gauss1, CCCenter, skybg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test output using the first fits file name in the list from above\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_fit_phot_time(fitsfilenames[0], guesscenter = None)#[160,160]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper function to cycle through each fits file name in the list of fits files from user input\n",
    "---\n",
    "\n",
    "Takes in a list of fits file names, loops over them in the crux function above, stores each entry (output from crux) into a dataframe for later storage and processing.\n",
    "\n",
    "Input:\n",
    "    1. List of fits file names to be loaded\n",
    "    2. Initial guess location of star\n",
    "    3. Subframe size to compute centering and photometry within\n",
    "    4. Aperature radius to compute photometry over\n",
    "    5. Predicted with of PSF (nyquist sampling = 2)\n",
    "Operation:\n",
    "    1. Loop over each file in the list of fits files\n",
    "    2. Send the fits file names to the crux function\n",
    "    3. Receive output list of aper phot, gauss centers/widths/amplitudes, cross-corr centers, sky background\n",
    "    4. Input the above computed values in the master data frame for stroage and later processing\n",
    "Outputs:\n",
    "    1. Master dataframe containing list of aper phot, gauss centers/widths/amplitudes, cross-corr centers, sky bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loads_fits_phots_times(fitsfiles, guesscenter = None, subframesize = [10,10], aperrad = [5], stddev0 = 2.0):\n",
    "    '''\n",
    "    'sky background'\n",
    "    'cross correlation center'\n",
    "    'gaussian center'\n",
    "    'gaussian width'\n",
    "    'gaussian ampitude'\n",
    "    'aperture photometry dictionary' or 'aperture photometry dataframe'\n",
    "    the keys to the aperture photometry dictionary or data frame will be the float values of the aperture radii\n",
    "    'time' (in days?)\n",
    "    '''\n",
    "    \n",
    "    print 'Need to add multiple aperture raddii usage'\n",
    "    columnNames = ['filename'           , 'aperture phot %.1f' %aperrad[0], \n",
    "                   'time'               , 'gaussian amplitude' , \n",
    "                   'gaussian y center'  , 'gaussian x center'  , \n",
    "                   'gaussian y width'   , 'gaussian x width'   , \n",
    "                   'cross corr y center', 'cross corr x center', \n",
    "                   'sky background']\n",
    "\n",
    "    master_output_df = DataFrame(columns=columnNames)\n",
    "    for fitsfile in fitsfiles:\n",
    "        columnInputs = load_fit_phot_time(fitsfile, guesscenter  = guesscenter, \n",
    "                                                    subframesize = subframesize, \n",
    "                                                    aperrad      = aperrad, \n",
    "                                                    stddev0      = stddev0)\n",
    "        #\n",
    "        master_output_df.loc[len(master_output_df)] = columnInputs\n",
    "    \n",
    "    return master_output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Master Output DataFrame and Print Out Table Thereof\n",
    "---\n",
    "\n",
    "The table below is the entire data set computed from the wrapper to the crux function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "master_output_df = loads_fits_phots_times(fitsfilenames, guesscenter = None, \n",
    "                                          subframesize = [10,10], aperrad = [3], stddev0 = 2.0)\n",
    "master_output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Scatter Matrix to Cross Compare All Values with Eachother\n",
    "---\n",
    "\n",
    "The scatter matrix is a pandas data frame function that plots every column of the data frame against every other column of the data frame in a matrix format.\n",
    "\n",
    "The diagonal is a kernel density estimator (default: histogram) as a metric on the specific column distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scatter_matrix(master_output_df.drop('filename',1), diagonal='kde', figsize=(14,12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot All Values as Function of Time and Gaussian Centers\n",
    "---\n",
    "\n",
    "Cycle through all columns that have numerical data and plot them against time.\n",
    "\n",
    "For special cases, plot the gaussian X and Y centers vs aperture photometry values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def renorm(arr):\n",
    "    if arr.dtype == 'float64':\n",
    "        return arr - median(arr)\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "master_output_df.apply(renorm, axis=0)\n",
    "\n",
    "fig = figure(figsize=(14,12))\n",
    "for k, key in enumerate(master_output_df.keys()):\n",
    "    ax  = fig.add_subplot(len(master_output_df.keys()), 1, k+1)\n",
    "    if not key in ['time', 'filename']:\n",
    "        ax.plot(master_output_df['time'], master_output_df[key])\n",
    "        if k == len(master_output_df.keys()) - 1:\n",
    "            ax.set_xlabel('time')\n",
    "        else:\n",
    "            ax.set_xticklabels([])\n",
    "        \n",
    "        ax.set_ylabel(key.replace('gaussian', 'gauss').replace('background', 'bg').replace(' ', '\\n'))\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(nbins=3))\n",
    "\n",
    "ax  = fig.add_subplot(len(master_output_df.keys()), 1, 1)\n",
    "ax.plot(master_output_df['gaussian y center'], master_output_df['aperture phot 3.0'], 'o')\n",
    "ax.set_ylabel('aperture phot 3.0'.replace(' ', '\\n'))\n",
    "ax.set_xlabel('gauss y center')\n",
    "ax.yaxis.set_major_locator(MaxNLocator(nbins=3))\n",
    "\n",
    "ax  = fig.add_subplot(len(master_output_df.keys()), 1, 3)\n",
    "ax.plot(master_output_df['gaussian x center'], master_output_df['aperture phot 3.0'], 'o')\n",
    "ax.set_ylabel('aperture phot 3.0'.replace(' ', '\\n'))\n",
    "ax.set_xlabel('gauss x center')\n",
    "ax.yaxis.set_major_locator(MaxNLocator(nbins=3))\n",
    "\n",
    "subplots_adjust( hspace=1 )\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The Following is Strictly from My Python Routine \n",
    "===\n",
    "---\n",
    "\n",
    "This routine is for later plotting with html interface. It is not useful for the above routines yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "\n",
    "N = 10000\n",
    "\n",
    "x = np.random.normal(0,np.pi, N)\n",
    "y = np.sin(x) + np.random.normal(0,0.2,N)\n",
    "\n",
    "output_file('test_bokeh2.html', title='scatter 10k points')\n",
    "\n",
    "p = figure(webgl=False)\n",
    "p.scatter(x,y,alpha=0.1)\n",
    "show(p)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
